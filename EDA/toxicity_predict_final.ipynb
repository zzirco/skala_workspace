{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7edb5c7",
   "metadata": {},
   "source": [
    "\n",
    "# 화합물 독성예측 (최종버전) — 전체 데이터로 학습 + 예측 CSV 생성\n",
    "\n",
    "이 노트북은 **train.csv** 전체로 학습하고, **predict_input.csv**에 대해 독성 예측 결과를 생성합니다.\n",
    "\n",
    "- NaN/Inf 안전 처리 (라벨/피처)\n",
    "- SimpleImputer(median) + StandardScaler + (옵션)다항식 특성\n",
    "- 모델 후보: LogisticRegression, RandomForest, HistGradientBoosting, SVC\n",
    "- 성능 비교 후 F1 기준 최적 모델 선택\n",
    "- `predict_output.csv`로 예측 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51520bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install -q scikit-learn pandas numpy matplotlib joblib\n",
    "\n",
    "import os, joblib, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, average_precision_score, classification_report,\n",
    "                             confusion_matrix)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810fa534",
   "metadata": {},
   "source": [
    "## 1) 데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b7c1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 파일 경로 자동 탐색\n",
    "train_path = next((p for p in [\"/mnt/data/train.csv\", \"./train.csv\", \"/content/train.csv\"] if Path(p).exists()), None)\n",
    "pred_path = next((p for p in [\"/mnt/data/predict_input.csv\", \"./predict_input.csv\", \"/content/predict_input.csv\"] if Path(p).exists()), None)\n",
    "assert train_path, \"train.csv 파일이 필요합니다.\"\n",
    "assert pred_path, \"predict_input.csv 파일이 필요합니다.\"\n",
    "\n",
    "print(f\"[train 파일] {train_path}\")\n",
    "print(f\"[predict 파일] {pred_path}\")\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "pred_df = pd.read_csv(pred_path)\n",
    "\n",
    "# 라벨 정리\n",
    "train_df['label_num'] = pd.to_numeric(train_df['label'], errors='coerce')\n",
    "valid_mask = train_df['label_num'].isin([0,1])\n",
    "print(\"유효하지 않은 라벨 제거:\", (~valid_mask).sum())\n",
    "train_df = train_df[valid_mask].copy()\n",
    "y = train_df['label_num'].astype(int)\n",
    "\n",
    "# 피처 선택 + 파생\n",
    "base_cols = [c for c in ['MolWt','clogp','sa_score','qed'] if c in train_df.columns]\n",
    "if all(c in train_df.columns for c in ['MolWt','clogp']):\n",
    "    train_df['MW_x_clogP'] = train_df['MolWt'] * train_df['clogp']\n",
    "    base_cols.append('MW_x_clogP')\n",
    "\n",
    "X = train_df[base_cols].replace([np.inf,-np.inf], np.nan)\n",
    "print(\"사용 피처:\", base_cols)\n",
    "print(\"결측치 개수:\\n\", X.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8fb6ea",
   "metadata": {},
   "source": [
    "## 2) 모델 학습 및 성능 평가 (CV 기반)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aba49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "steps = [('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())]\n",
    "if len(base_cols) > 1:\n",
    "    steps.append(('poly', PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)))\n",
    "preprocess = Pipeline(steps=steps)\n",
    "\n",
    "pipelines = {\n",
    "    \"LogReg\": Pipeline([(\"prep\", preprocess),\n",
    "                        (\"clf\", LogisticRegression(max_iter=1000, random_state=RANDOM_STATE))]),\n",
    "    \"RF\": Pipeline([(\"prep\", preprocess),\n",
    "                    (\"clf\", RandomForestClassifier(n_estimators=300, n_jobs=-1, random_state=RANDOM_STATE))]),\n",
    "    \"HGB\": Pipeline([(\"prep\", preprocess),\n",
    "                     (\"clf\", HistGradientBoostingClassifier(learning_rate=0.1, random_state=RANDOM_STATE))]),\n",
    "    \"SVC\": Pipeline([(\"prep\", preprocess),\n",
    "                     (\"clf\", SVC(C=1.0, kernel='rbf', probability=True, random_state=RANDOM_STATE))])\n",
    "}\n",
    "\n",
    "param_spaces = {\n",
    "    \"LogReg\": {\"clf__C\": np.logspace(-2, 2, 10)},\n",
    "    \"RF\": {\"clf__n_estimators\":[200,300,400], \"clf__max_depth\":[None,5,10,15], \"clf__min_samples_leaf\":[1,2,4]},\n",
    "    \"HGB\": {\"clf__learning_rate\":[0.05,0.1,0.2], \"clf__max_depth\":[None,5,10], \"clf__l2_regularization\":[0.0,0.01,0.1]},\n",
    "    \"SVC\": {\"clf__C\": np.logspace(-2, 2, 6), \"clf__gamma\":[\"scale\",\"auto\"]}\n",
    "}\n",
    "\n",
    "results, best_models = {}, {}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "for name, pipe in pipelines.items():\n",
    "    print(f\"\\n=== {name} RandomizedSearchCV (CV=5) ===\")\n",
    "    search = RandomizedSearchCV(pipe, param_spaces[name], n_iter=10, scoring='f1', n_jobs=-1, cv=cv, random_state=RANDOM_STATE, verbose=1)\n",
    "    search.fit(X, y)\n",
    "    best_models[name] = search.best_estimator_\n",
    "    cv_f1 = cross_val_score(search.best_estimator_, X, y, cv=cv, scoring='f1').mean()\n",
    "    print(f\"[{name}] best params:\", search.best_params_)\n",
    "    print(f\"[{name}] mean CV F1: {cv_f1:.4f}\")\n",
    "    results[name] = {\"cv_f1\": cv_f1}\n",
    "\n",
    "summary = pd.DataFrame(results).T.sort_values(\"cv_f1\", ascending=False)\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b600cb29",
   "metadata": {},
   "source": [
    "## 3) 최고 모델 선택 및 전체 데이터 재학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63fddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_name = summary.index[0]\n",
    "best_model = best_models[best_name]\n",
    "print(f\"[BEST MODEL] {best_name}\")\n",
    "\n",
    "# 전체 데이터로 최종 재학습\n",
    "best_model.fit(X, y)\n",
    "joblib.dump(best_model, \"best_toxicity_model.joblib\")\n",
    "print(\"모델 저장 완료: best_toxicity_model.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bca87c",
   "metadata": {},
   "source": [
    "## 4) 예측 수행 및 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9b22f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_features(df_in: pd.DataFrame, base_cols=None) -> pd.DataFrame:\n",
    "    if base_cols is None:\n",
    "        base_cols = [c for c in ['MolWt','clogp','sa_score','qed'] if c in df_in.columns]\n",
    "    df_in = df_in.copy()\n",
    "    if all(c in df_in.columns for c in ['MolWt','clogp']):\n",
    "        df_in['MW_x_clogP'] = df_in['MolWt'] * df_in['clogp']\n",
    "        if 'MW_x_clogP' not in base_cols:\n",
    "            base_cols = [*base_cols, 'MW_x_clogP']\n",
    "    return df_in[base_cols].replace([np.inf,-np.inf], np.nan)\n",
    "\n",
    "X_pred = prepare_features(pred_df, base_cols)\n",
    "pred_label = best_model.predict(X_pred)\n",
    "pred_proba = best_model.predict_proba(X_pred)[:,1]\n",
    "\n",
    "out_df = pred_df.copy()\n",
    "out_df['pred_label'] = pred_label\n",
    "out_df['pred_proba'] = pred_proba\n",
    "out_df.to_csv(\"predict_output.csv\", index=False)\n",
    "print(\"✅ 예측 결과 저장 완료: predict_output.csv\")\n",
    "out_df.head()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}