{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CasheBackedEmbeddings\n",
    "\n",
    "1. 개요\n",
    "    - 임베딩 계산 결과를 캐싱 \n",
    "    - 불필요한 API 호출을 방지하고 성능을 최적화 하기 위한 도구 \n",
    "\n",
    "2. 주요 특징 \n",
    "    - 중복 작업 방지:\n",
    "        - 동일한 텍스트에 대해 이미 게산된 임베딩 결과 재사용 \n",
    "        - 동일 요청에 대해 API 호출을 반복하지 않음 \n",
    "    - 성능 최적화:\n",
    "        - 임베딩 결과를 캐시에서 읽어오기 때문에 처리 속도가 크게 향상 \n",
    "        - 대규모 데이터나 실시간 응답 속도가 중요한 어플리케이션에서 유용\n",
    "\n",
    "\n",
    "[Reference] https://python.langchain.com/docs/how_to/caching_embeddings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain_community.vectorstores.faiss import FAISS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 정의\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# 로컬 파일 저장소 정의/초기화\n",
    "store = LocalFileStore('./cache/')\n",
    "\n",
    "# 캐시 지원하는 임베딩 설정 \n",
    "# namespace: 기본 임베딩과 저장소를 사용하여 캐시 지원 임베딩 생성\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    underlying_embeddings=embeddings,\n",
    "    document_embedding_cache=store,\n",
    "    namespace=embeddings.model, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.embeddings.cache.CacheBackedEmbeddings at 0x13d407f10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 캐싱된 임베딩 확인 \n",
    "cached_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 위치 정의 \n",
    "file_path = './data/appendix-keywords.txt'\n",
    "\n",
    "# 문서 로딩 \n",
    "loader = TextLoader(file_path).load()\n",
    "\n",
    "# 문서 분할 정의 \n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "\n",
    "# 문서 분할 \n",
    "documents = text_splitter.split_documents(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 μs, sys: 0 ns, total: 2 μs\n",
      "Wall time: 4.05 μs\n"
     ]
    }
   ],
   "source": [
    "# 벡터스토어 저장 \n",
    "%time\n",
    "\n",
    "vector_stores = FAISS.from_documents(documents, cached_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캐싱된 임베딩 파일 확인:\n",
      " - ./cache/text-embedding-ada-0020fd71f95-1342-512d-9d5b-3e3ab3c6bbe0\n",
      " - ./cache/text-embedding-ada-00274ae75af-9058-555e-aefa-082f0b4e0560\n",
      " - ./cache/text-embedding-ada-00241e7391b-b68f-5e9f-bb07-3609bb83c3e2\n",
      " - ./cache/text-embedding-ada-0027494a7c8-3399-52a1-85ef-f4d0a563d31f\n",
      " - ./cache/text-embedding-ada-0029db9e1cd-62d8-50fc-94f4-24bef3cacaf5\n",
      " - ./cache/text-embedding-ada-002cc824f84-d691-544f-9d9c-ca7e45470bb2\n",
      " - ./cache/text-embedding-ada-0022112b0ec-6ade-59c9-b09c-755b33c3d32c\n"
     ]
    }
   ],
   "source": [
    "print(\"캐싱된 임베딩 파일 확인:\")\n",
    "for root, dirs, files in os.walk('./cache/'):\n",
    "    for file in files:\n",
    "        print(f\" - {os.path.join(root, file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "캐싱된 특정 문서 임베딩 확인:\n",
      "문서 내용: Semantic Search\n",
      "\n",
      "정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을...\n",
      "임베딩 벡터 길이: 1536\n",
      "임베딩 벡터 예시: [-0.03266245126724243, -2.554550746936002e-06, 0.007919179275631905, -0.023124800994992256, -0.042786210775375366]...\n",
      "\n",
      "문서 내용: 정의: SQL(Structured Query Language)은 데이터베이스에서 데이터를 ...\n",
      "임베딩 벡터 길이: 1536\n",
      "임베딩 벡터 예시: [-0.01606258936226368, -0.006327888462692499, 0.009661508724093437, -0.02922406606376171, -0.0394977368414402]...\n",
      "\n",
      "문서 내용: 정의: HuggingFace는 자연어 처리를 위한 다양한 사전 훈련된 모델과 도구를 제공하...\n",
      "임베딩 벡터 길이: 1536\n",
      "임베딩 벡터 예시: [-0.03586680442094803, 0.0001885255624074489, 0.013284999877214432, -0.007410496473312378, -0.015427306294441223]...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n캐싱된 특정 문서 임베딩 확인:\")\n",
    "for doc in documents[:3]:  # 첫 3개의 문서에 대해 확인\n",
    "    print(f\"문서 내용: {doc.page_content[:50]}...\")  # 내용 일부 출력\n",
    "    vector = cached_embeddings.embed_query(doc.page_content)\n",
    "    print(f\"임베딩 벡터 길이: {len(vector)}\")\n",
    "    print(f\"임베딩 벡터 예시: {vector[:5]}...\\n\")  # 일부 벡터 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "** End of Documents **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-t0JhnSEV-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
